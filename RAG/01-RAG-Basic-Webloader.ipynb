{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b82288e",
   "metadata": {},
   "source": [
    "# RAG 기본 구조 이해하기\n",
    "\n",
    "## 1. 사전작업(Pre-processing) - 1~4 단계\n",
    "\n",
    "![rag-1.png](./assets/rag-1.png)\n",
    "\n",
    "![rag-1-graphic](./assets/rag-graphic-1.png)\n",
    "\n",
    "사전 작업 단계에서는 데이터 소스를 Vector DB (저장소) 에 문서를 로드-분할-임베딩-저장 하는 4단계를 진행합니다.\n",
    "\n",
    "- 1단계 문서로드(Document Load): 문서 내용을 불러옵니다.\n",
    "- 2단계 분할(Text Split): 문서를 특정 기준(Chunk) 으로 분할합니다.\n",
    "- 3단계 임베딩(Embedding): 분할된(Chunk) 를 임베딩하여 저장합니다.\n",
    "- 4단계 벡터DB 저장: 임베딩된 Chunk 를 DB에 저장합니다.\n",
    "\n",
    "## 2. RAG 수행(RunTime) - 5~8 단계\n",
    "\n",
    "![rag-2.png](./assets/rag-2.png)\n",
    "\n",
    "![](./assets/rag-graphic-2.png)\n",
    "\n",
    "- 5단계 검색기(Retriever): 쿼리(Query) 를 바탕으로 DB에서 검색하여 결과를 가져오기 위하여 리트리버를 정의합니다. 리트리버는 검색 알고리즘이며(Dense, Sparse) 리트리버로 나뉘게 됩니다. \n",
    "  - **Dense**: 유사도 기반 검색(FAISS, DPR)\n",
    "  - **Sparse**: 키워드 기반 검색(BM25, TF-IDF)\n",
    "- 6단계 프롬프트: RAG 를 수행하기 위한 프롬프트를 생성합니다. 프롬프트의 context 에는 문서에서 검색된 내용이 입력됩니다. 프롬프트 엔지니어링을 통하여 답변의 형식을 지정할 수 있습니다.\n",
    "- 7단계 LLM: 모델을 정의합니다.(GPT-3.5, GPT-4, Claude, etc..)\n",
    "- 8단계 Chain: 프롬프트 - LLM - 출력 에 이르는 체인을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c423a8",
   "metadata": {},
   "source": [
    "## 환경설정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a224fd32",
   "metadata": {},
   "source": [
    "API KEY 를 설정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "418ab505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc09d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain_google_genai in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.7)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.5.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: langchain_text_splitters in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (0.3.68)\n",
      "Collecting langchain<1.0.0,>=0.3.26 (from langchain_community)\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\n",
      "  Downloading sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_community) (0.4.5)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain_community)\n",
      "  Downloading numpy-2.3.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.9/60.9 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_google_genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_google_genai) (0.6.18)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_google_genai) (2.11.7)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Using cached langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.73-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata (76 kB)\n",
      "     ---------------------------------------- 0.0/76.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 76.3/76.3 kB ? eta 0:00:00\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (6.31.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.7/44.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.7.9)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Downloading greenlet-3.2.3-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.73.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.5 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.5 MB 13.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.2/2.5 MB 15.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 14.7 MB/s eta 0:00:00\n",
      "Downloading langgraph-0.5.3-py3-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 143.8/143.8 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl (449 kB)\n",
      "   ---------------------------------------- 0.0/449.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 449.3/449.3 kB 14.2 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   -------------------------------------- - 1.0/1.0 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 21.3 MB/s eta 0:00:00\n",
      "Using cached langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
      "Downloading langgraph_sdk-0.1.73-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB ? eta 0:00:00\n",
      "Downloading numpy-2.3.1-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/12.7 MB 31.1 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.0/12.7 MB 25.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.1/12.7 MB 24.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.3/12.7 MB 24.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.4/12.7 MB 24.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.6/12.7 MB 25.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.9/12.7 MB 25.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.7 MB 25.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.8/12.7 MB 24.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/12.7 MB 22.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.8/12.7 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.7 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 21.8 MB/s eta 0:00:00\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.2/45.2 kB ? eta 0:00:00\n",
      "Downloading sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.1/2.1 MB 34.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 26.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 26.9 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl (43 kB)\n",
      "   ---------------------------------------- 0.0/43.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 43.9/43.9 kB ? eta 0:00:00\n",
      "Downloading greenlet-3.2.3-cp312-cp312-win_amd64.whl (297 kB)\n",
      "   ---------------------------------------- 0.0/297.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 297.8/297.8 kB 18.0 MB/s eta 0:00:00\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.9/50.9 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.4 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 61.4/121.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 121.4/121.4 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.7/86.7 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: xxhash, python-dotenv, propcache, ormsgpack, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, greenlet, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, aiosignal, pydantic-settings, langgraph-sdk, dataclasses-json, aiohttp, langgraph-checkpoint, langgraph-prebuilt, langchain, langgraph, langchain_community\n",
      "Successfully installed SQLAlchemy-2.0.41 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.7.0 greenlet-3.2.3 httpx-sse-0.4.1 langchain-0.3.26 langchain_community-0.3.27 langgraph-0.5.3 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.73 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 numpy-2.3.1 ormsgpack-1.10.0 propcache-0.3.2 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0 xxhash-3.5.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script dotenv.exe is installed in 'c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community langchain_google_genai langgraph langchain_text_splitters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae2d96e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.11.0.post1)\n",
      "Collecting langchain_teddynote\n",
      "  Downloading langchain_teddynote-0.3.45-py3-none-any.whl.metadata (867 bytes)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (4.14.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (2.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: langchain in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_teddynote) (0.3.26)\n",
      "Requirement already satisfied: langgraph in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_teddynote) (0.5.3)\n",
      "Collecting kiwipiepy (from langchain_teddynote)\n",
      "  Downloading kiwipiepy-0.21.0-cp312-cp312-win_amd64.whl.metadata (1.3 kB)\n",
      "Collecting rank_bm25 (from langchain_teddynote)\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pinecone-client[grpc] (from langchain_teddynote)\n",
      "  Downloading pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pinecone-text (from langchain_teddynote)\n",
      "  Downloading pinecone_text-0.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting olefile (from langchain_teddynote)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting pdf2image (from langchain_teddynote)\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting openai (from langchain_teddynote)\n",
      "  Downloading openai-1.97.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anthropic (from langchain_teddynote)\n",
      "  Downloading anthropic-0.57.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting deepl (from langchain_teddynote)\n",
      "  Downloading deepl-1.22.0-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting feedparser (from langchain_teddynote)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tavily-python (from langchain_teddynote)\n",
      "  Downloading tavily_python-0.7.9-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pandas (from langchain_teddynote)\n",
      "  Downloading pandas-2.3.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anthropic->langchain_teddynote) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic->langchain_teddynote)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anthropic->langchain_teddynote) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic->langchain_teddynote)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anthropic->langchain_teddynote) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anthropic->langchain_teddynote) (1.3.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deepl->langchain_teddynote) (2.32.4)\n",
      "Collecting sgmllib3k (from feedparser->langchain_teddynote)\n",
      "  Using cached sgmllib3k-1.0.0-py3-none-any.whl\n",
      "Collecting kiwipiepy_model<0.22,>=0.21 (from kiwipiepy->langchain_teddynote)\n",
      "  Downloading kiwipiepy_model-0.21.0.tar.gz (35.5 MB)\n",
      "     ---------------------------------------- 0.0/35.5 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.5/35.5 MB 15.4 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 1.2/35.5 MB 14.5 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 2.1/35.5 MB 16.4 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 2.9/35.5 MB 16.8 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 3.9/35.5 MB 17.6 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 4.9/35.5 MB 18.4 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 5.9/35.5 MB 18.9 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 7.0/35.5 MB 19.3 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 8.1/35.5 MB 19.9 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 9.2/35.5 MB 20.3 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 10.2/35.5 MB 21.1 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 11.5/35.5 MB 22.6 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 12.8/35.5 MB 24.2 MB/s eta 0:00:01\n",
      "     --------------- ----------------------- 14.1/35.5 MB 25.2 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 15.4/35.5 MB 26.2 MB/s eta 0:00:01\n",
      "     ------------------ -------------------- 16.7/35.5 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------- ------------------- 18.1/35.5 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------- ----------------- 19.5/35.5 MB 28.5 MB/s eta 0:00:01\n",
      "     ---------------------- ---------------- 20.7/35.5 MB 28.4 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 21.3/35.5 MB 29.8 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 23.1/35.5 MB 28.4 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 24.4/35.5 MB 27.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 25.7/35.5 MB 27.3 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 27.0/35.5 MB 28.4 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 28.1/35.5 MB 28.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 29.3/35.5 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 30.4/35.5 MB 27.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 31.8/35.5 MB 29.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 33.0/35.5 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 34.2/35.5 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  35.5/35.5 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  35.5/35.5 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------------- 35.5/35.5 MB 23.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tqdm (from kiwipiepy->langchain_teddynote)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain->langchain_teddynote) (0.3.68)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain->langchain_teddynote) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain->langchain_teddynote) (0.4.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain->langchain_teddynote) (2.0.41)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain->langchain_teddynote) (6.0.2)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph->langchain_teddynote) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph->langchain_teddynote) (0.5.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph->langchain_teddynote) (0.1.73)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph->langchain_teddynote) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\blake\\appdata\\roaming\\python\\python312\\site-packages (from pandas->langchain_teddynote) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->langchain_teddynote) (2025.2)\n",
      "Collecting tzdata>=2022.7 (from pandas->langchain_teddynote)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pillow (from pdf2image->langchain_teddynote)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client[grpc]->langchain_teddynote) (2025.7.9)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.66.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client[grpc]->langchain_teddynote) (1.70.0)\n",
      "Requirement already satisfied: grpcio>=1.59.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client[grpc]->langchain_teddynote) (1.73.1)\n",
      "Collecting lz4>=3.1.3 (from pinecone-client[grpc]->langchain_teddynote)\n",
      "  Downloading lz4-4.4.4-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client[grpc]->langchain_teddynote)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting protobuf<6.0,>=5.29 (from pinecone-client[grpc]->langchain_teddynote)\n",
      "  Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting protoc-gen-openapiv2<0.0.2,>=0.0.1 (from pinecone-client[grpc]->langchain_teddynote)\n",
      "  Downloading protoc_gen_openapiv2-0.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client[grpc]->langchain_teddynote) (2.5.0)\n",
      "Collecting mmh3<5.0.0,>=4.1.0 (from pinecone-text->langchain_teddynote)\n",
      "  Downloading mmh3-4.1.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting nltk<4.0.0,>=3.9.1 (from pinecone-text->langchain_teddynote)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy<3.0,>=1.25.0 (from faiss-cpu)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-text->langchain_teddynote) (1.1.1)\n",
      "Collecting types-requests<3.0.0,>=2.25.0 (from pinecone-text->langchain_teddynote)\n",
      "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tiktoken>=0.5.1 (from tavily-python->langchain_teddynote)\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic->langchain_teddynote) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic->langchain_teddynote) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic->langchain_teddynote) (0.16.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain->langchain_teddynote) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain->langchain_teddynote) (1.33)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph->langchain_teddynote) (1.10.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph->langchain_teddynote) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain->langchain_teddynote) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith>=0.1.17->langchain->langchain_teddynote) (0.23.0)\n",
      "Collecting click (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain_teddynote)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain_teddynote)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain_teddynote)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic->langchain_teddynote) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic->langchain_teddynote) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic->langchain_teddynote) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\blake\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->langchain_teddynote) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->deepl->langchain_teddynote) (3.4.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->langchain_teddynote) (3.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\blake\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->kiwipiepy->langchain_teddynote) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\blake\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain->langchain_teddynote) (3.0.0)\n",
      "Downloading langchain_teddynote-0.3.45-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.6/50.6 kB ? eta 0:00:00\n",
      "Downloading anthropic-0.57.1-py3-none-any.whl (292 kB)\n",
      "   ---------------------------------------- 0.0/292.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 292.8/292.8 kB ? eta 0:00:00\n",
      "Downloading deepl-1.22.0-py3-none-any.whl (43 kB)\n",
      "   ---------------------------------------- 0.0/43.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 43.7/43.7 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "   ---------------------------------------- 0.0/81.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 81.3/81.3 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading kiwipiepy-0.21.0-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 1.4/2.4 MB 29.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 25.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 25.6 MB/s eta 0:00:00\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "   ---------------------------------------- 0.0/114.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 114.6/114.6 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading openai-1.97.0-py3-none-any.whl (764 kB)\n",
      "   ---------------------------------------- 0.0/765.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 765.0/765.0 kB 47.2 MB/s eta 0:00:00\n",
      "Downloading pandas-2.3.1-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.2/11.0 MB 37.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.4/11.0 MB 30.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.8/11.0 MB 30.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.0/11.0 MB 29.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 29.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.6/11.0 MB 24.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.0/11.0 MB 22.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 21.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.0 MB 21.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 22.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 22.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 21.1 MB/s eta 0:00:00\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pinecone_text-0.10.0-py3-none-any.whl (22 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/15.5 MB 20.7 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 2.2/15.5 MB 22.8 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.4/15.5 MB 27.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.6/15.5 MB 26.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.8/15.5 MB 26.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.0/15.5 MB 26.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.2/15.5 MB 26.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.4/15.5 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.5 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.9/15.5 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.2/15.5 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.5/15.5 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 25.2 MB/s eta 0:00:00\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Downloading tavily_python-0.7.9-py3-none-any.whl (15 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl (206 kB)\n",
      "   ---------------------------------------- 0.0/206.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 206.2/206.2 kB ? eta 0:00:00\n",
      "Downloading lz4-4.4.4-cp312-cp312-win_amd64.whl (99 kB)\n",
      "   ---------------------------------------- 0.0/99.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 99.9/99.9 kB ? eta 0:00:00\n",
      "Downloading mmh3-4.1.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 1.4/1.5 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 23.7 MB/s eta 0:00:00\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading protoc_gen_openapiv2-0.0.1-py3-none-any.whl (7.9 kB)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 894.9/894.9 kB 27.6 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading pillow-11.3.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.3/7.0 MB 27.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.4/7.0 MB 25.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.6/7.0 MB 26.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.9/7.0 MB 28.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.2/7.0 MB 28.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.0/7.0 MB 27.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 24.8 MB/s eta 0:00:00\n",
      "Downloading pinecone_client-6.0.0-py3-none-any.whl (6.7 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 273.6/273.6 kB 17.6 MB/s eta 0:00:00\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Building wheels for collected packages: kiwipiepy_model\n",
      "  Building wheel for kiwipiepy_model (pyproject.toml): started\n",
      "  Building wheel for kiwipiepy_model (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for kiwipiepy_model: filename=kiwipiepy_model-0.21.0-py3-none-any.whl size=35593257 sha256=1aa5ff41b6dc408e766f98fce18f12d6af5bc5cf5b12a2d88cb80241e4d685ef\n",
      "  Stored in directory: c:\\users\\blake\\appdata\\local\\pip\\cache\\wheels\\5f\\94\\81\\3e8b1478625f1bdb3b72733dfe3086a8f77a8f25db2b1d746b\n",
      "Successfully built kiwipiepy_model\n",
      "Installing collected packages: sgmllib3k, mmh3, kiwipiepy_model, tzdata, types-requests, tqdm, regex, protobuf, pinecone-plugin-interface, pillow, olefile, numpy, lz4, joblib, jiter, feedparser, distro, click, tiktoken, rank_bm25, pinecone-client, pdf2image, pandas, nltk, kiwipiepy, deepl, tavily-python, protoc-gen-openapiv2, pinecone-text, openai, anthropic, langchain_teddynote\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.31.1\n",
      "    Uninstalling protobuf-6.31.1:\n",
      "      Successfully uninstalled protobuf-6.31.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.1\n",
      "    Uninstalling numpy-2.3.1:\n",
      "      Successfully uninstalled numpy-2.3.1\n",
      "Successfully installed anthropic-0.57.1 click-8.2.1 deepl-1.22.0 distro-1.9.0 feedparser-6.0.11 jiter-0.10.0 joblib-1.5.1 kiwipiepy-0.21.0 kiwipiepy_model-0.21.0 langchain_teddynote-0.3.45 lz4-4.4.4 mmh3-4.1.0 nltk-3.9.1 numpy-1.26.4 olefile-0.47 openai-1.97.0 pandas-2.3.1 pdf2image-1.17.0 pillow-11.3.0 pinecone-client-6.0.0 pinecone-plugin-interface-0.0.7 pinecone-text-0.10.0 protobuf-5.29.5 protoc-gen-openapiv2-0.0.1 rank_bm25-0.2.2 regex-2024.11.6 sgmllib3k-1.0.0 tavily-python-0.7.9 tiktoken-0.9.0 tqdm-4.67.1 types-requests-2.32.4.20250611 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\~upb'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: The script distro.exe is installed in 'c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nltk.exe is installed in 'c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script deepl.exe is installed in 'c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openai.exe is installed in 'c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.73.1 requires protobuf<7.0.0,>=6.30.0, but you have protobuf 5.29.5 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4 faiss-cpu langchain_teddynote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024d0c5",
   "metadata": {},
   "source": [
    "LangChain으로 구축한 애플리케이션은 여러 단계에 걸쳐 LLM 호출을 여러 번 사용하게 됩니다. 이러한 애플리케이션이 점점 더 복잡해짐에 따라, 체인이나 에이전트 내부에서 정확히 무슨 일이 일어나고 있는지 조사할 수 있는 능력이 매우 중요해집니다. 이를 위한 최선의 방법은 [LangSmith](https://smith.langchain.com)를 사용하는 것입니다.\n",
    "\n",
    "LangSmith가 필수는 아니지만, 유용합니다. LangSmith를 사용하고 싶다면, 위의 링크에서 가입한 후, 로깅 추적을 시작하기 위해 환경 변수를 설정해야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3edbbf89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_teddynote'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# LangSmith 추적을 설정합니다. https://smith.langchain.com\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# !pip install -qU langchain-teddynote\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_teddynote\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 프로젝트 이름을 입력합니다.\u001b[39;00m\n\u001b[32m      6\u001b[39m logging.langsmith(\u001b[33m\"\u001b[39m\u001b[33mCH12-RAG\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_teddynote'"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH12-RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de11a49",
   "metadata": {},
   "source": [
    "## 네이버 뉴스 기반 QA(Question-Answering) 챗봇\n",
    "\n",
    "이번 튜토리얼에는 네이버 뉴스기사의 내용에 대해 질문할 수 있는 **뉴스기사 QA 앱** 을 구축할 것입니다.\n",
    "\n",
    "이 가이드에서는 OpenAI 챗 모델과 임베딩, 그리고 Chroma 벡터 스토어를 사용할 것입니다.\n",
    "\n",
    "먼저 다음의 과정을 통해 간단한 인덱싱 파이프라인과 RAG 체인을 약 20줄의 코드로 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ed3df",
   "metadata": {},
   "source": [
    "라이브러리\n",
    "\n",
    "- `bs4`는 웹 페이지를 파싱하기 위한 라이브러리입니다.\n",
    "- `langchain`은 AI와 관련된 다양한 기능을 제공하는 라이브러리로, 여기서는 특히 텍스트 분할(`RecursiveCharacterTextSplitter`), 문서 로딩(`WebBaseLoader`), 벡터 저장(`Chroma`, `FAISS`), 출력 파싱(`StrOutputParser`), 실행 가능한 패스스루(`RunnablePassthrough`) 등을 다룹니다.\n",
    "- `langchain_openai` 모듈을 통해 OpenAI의 챗봇(`ChatOpenAI`)과 임베딩(`OpenAIEmbeddings`) 기능을 사용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3d1b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595217a5",
   "metadata": {},
   "source": [
    "웹 페이지의 내용을 로드하고, 텍스트를 청크로 나누어 인덱싱하는 과정을 거친 후, 관련된 텍스트 스니펫을 검색하여 새로운 내용을 생성하는 과정을 구현합니다.\n",
    "\n",
    "`WebBaseLoader`는 지정된 웹 페이지에서 필요한 부분만을 파싱하기 위해 `bs4.SoupStrainer`를 사용합니다.\n",
    "\n",
    "[참고]\n",
    "\n",
    "- `bs4.SoupStrainer` 는 편리하게 웹에서 원하는 요소를 가져올 수 있도록 해줍니다.\n",
    "\n",
    "(예시)\n",
    "\n",
    "```python\n",
    "bs4.SoupStrainer(\n",
    "    \"div\",\n",
    "    attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f69f249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://n.news.naver.com/article/437/0000378416'}, page_content=\"\\n출산 직원에게 '1억원' 쏜다…회사의 파격적 저출생 정책\\n\\n\\n[앵커]올해 아이 낳을 계획이 있는 가족이라면 솔깃할 소식입니다. 정부가 저출생 대책으로 매달 주는 부모 급여, 0세 아이는 100만원으로 올렸습니다. 여기에 첫만남이용권, 아동수당까지 더하면 아이 돌까지 1년 동안 1520만원을 받습니다. 지자체도 경쟁하듯 지원에 나섰습니다. 인천시는 새로 태어난 아기, 18살될 때까지 1억원을 주겠다. 광주시도 17살될 때까지 7400만원 주겠다고 했습니다. 선거 때면 나타나서 아이 낳으면 현금 주겠다고 밝힌 사람이 있었죠. 과거에는 표만 노린 '황당 공약'이라는 비판이 따라다녔습니다. 그런데 지금은 출산율이 이보다 더 나쁠 수 없다보니, 이런 현금성 지원을 진지하게 정책화 하는 상황까지 온 겁니다. 게다가 기업들도 뛰어들고 있습니다. 이번에는 출산한 직원에게 단번에 1억원을 주겠다는 회사까지 나타났습니다.이상화 기자가 취재했습니다.[기자]한 그룹사가 오늘 파격적인 저출생 정책을 내놨습니다.2021년 이후 태어난 직원 자녀에 1억원씩, 총 70억원을 지원하고 앞으로도 이 정책을 이어가기로 했습니다.해당 기간에 연년생과 쌍둥이 자녀가 있으면 총 2억원을 받게 됩니다.[오현석/부영그룹 직원 : 아이 키우는 데 금전적으로 많이 힘든 세상이잖아요. 교육이나 생활하는 데 큰 도움이 될 거라 생각합니다.]만약 셋째까지 낳는 경우엔 국민주택을 제공하겠다는 뜻도 밝혔습니다.[이중근/부영그룹 회장 : 3년 이내에 세 아이를 갖는 분이 나올 것이고 따라서 주택을 제공할 수 있는 계기가 될 것으로 생각하고.][조용현/부영그룹 직원 : 와이프가 셋째도 갖고 싶어 했는데 경제적 부담 때문에 부정적이었거든요. (이제) 긍정적으로 생각할 수 있을 것 같습니다.]오늘 행사에서는, 회사가 제공하는 출산장려금은 받는 직원들의 세금 부담을 고려해 정부가 면세해달라는 제안도 나왔습니다.이같은 출산장려책은 점점 확산하는 분위기입니다.법정기간보다 육아휴직을 길게 주거나, 남성 직원의 육아휴직을 의무화한 곳도 있습니다.사내 어린이집을 밤 10시까지 운영하고 셋째를 낳으면 무조건 승진시켜 주기도 합니다.한 회사는 지난해 네쌍둥이를 낳은 직원에 의료비를 지원해 관심을 모았습니다.정부 대신 회사가 나서는 출산장려책이 사회적 분위기를 바꿀 거라는 기대가 커지는 가운데, 여력이 부족한 중소지원이 필요하다는 목소리도 나옵니다.[영상디자인 곽세미]\\n\\t\\t\\n\")]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "# 뉴스기사 내용을 로드하고, 청크로 나누고, 인덱싱합니다.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://n.news.naver.com/article/437/0000378416\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d5bce",
   "metadata": {},
   "source": [
    "`RecursiveCharacterTextSplitter`는 문서를 지정된 크기의 청크로 나눕니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e9bf670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a38783",
   "metadata": {},
   "source": [
    "`FAISS` 혹은 `Chroma`와 같은 vectorstore는 이러한 청크를 바탕으로 문서의 벡터 표현을 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
    "\n",
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a89f55",
   "metadata": {},
   "source": [
    "`vectorstore.as_retriever()`를 통해 생성된 검색기는 `hub.pull`로 가져온 프롬프트와 `ChatOpenAI` 모델을 사용하여 새로운 내용을 생성합니다.\n",
    "\n",
    "마지막으로, `StrOutputParser`는 생성된 결과를 문자열로 파싱합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a59f677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
    "검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\n",
    "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "\n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35016e46",
   "metadata": {},
   "source": [
    "hub 에서 `teddynote/rag-prompt-korean` 프롬프트를 다운로드 받아 입력할 수 있습니다. 이런 경우 별도의 프롬프트 작성과정이 생략됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = hub.pull(\"teddynote/rag-prompt-korean\")\n",
    "# prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d16128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\", temperature=0)\n",
    "\n",
    "\n",
    "# 체인을 생성합니다.\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9370eb",
   "metadata": {},
   "source": [
    "스트리밍 출력을 위하여 `stream_response` 를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78fed977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4948a029",
   "metadata": {},
   "source": [
    "> [LangSmith Trace 보기](https://smith.langchain.com/public/c6047a61-8f44-48e5-89eb-b1e8a6321cea/r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78275b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부영그룹은 2021년 이후 태어난 직원 자녀에게 1억원씩 지원하는 파격적인 저출생 정책을 발표했습니다. 연년생이나 쌍둥이 자녀가 있는 경우 총 2억원을 받게 되며, 셋째를 낳는 경우에는 국민주택을 제공하겠다는 뜻도 밝혔습니다. 또한, 회사는 출산장려금에 대한 직원들의 세금 부담을 고려하여 정부에 면세해달라는 제안도 했습니다.\n"
     ]
    }
   ],
   "source": [
    "answer = rag_chain.stream(\"부영그룹의 출산 장려 정책에 대해 설명해주세요.\")\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eec33e",
   "metadata": {},
   "source": [
    "> [LangSmith Trace 보기](https://smith.langchain.com/public/ed21d80e-b4da-4a08-823b-ed980db9c347/r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c96f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = rag_chain.stream(\"부영그룹은 출산 직원에게 얼마의 지원을 제공하나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044ceba",
   "metadata": {},
   "source": [
    "> [LangSmith Trace 보기](https://smith.langchain.com/public/df80c528-61d6-4c83-986a-3373a4039dae/r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = rag_chain.stream(\"정부의 저출생 대책을 bullet points 형식으로 작성해 주세요.\")\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c627d96",
   "metadata": {},
   "source": [
    "> [LangSmith Trace 보기](https://smith.langchain.com/public/1a613ee7-6eaa-482f-a45f-8c22b4e60fbf/r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = rag_chain.stream(\"부영그룹의 임직원 숫자는 몇명인가요?\")\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
